{\rtf1\ansi\ansicpg1252\cocoartf2638
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red202\green202\blue202;\red23\green23\blue23;\red140\green211\blue254;
\red194\green126\blue101;\red70\green137\blue204;}
{\*\expandedcolortbl;;\cssrgb\c83137\c83137\c83137;\cssrgb\c11765\c11765\c11765;\cssrgb\c61176\c86275\c99608;
\cssrgb\c80784\c56863\c47059;\cssrgb\c33725\c61176\c83922;}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh14640\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
\
Once docker is up, you can go to localhost:8080\
- password and username: airflow\
\
Once in the airflow UI\
- click on admin \'97> connections\
- type the things below in\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 {{\NeXTGraphic Screenshot 2022-09-26 at 3.52.24 PM.png \width28800 \height18000 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
https://gist.github.com/marclamberti/f45f872dea4dfd3eaa015a4a1af4b39b\
 {\field{\*\fldinst{HYPERLINK "https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/filesystem/index.html"}}{\fldrslt airflow.sensors.filesystem \'97 Airflow Documentation}}\
\
# task_id must be unique across all the operators you have in the same DAG \
# http_conn_id correspons to the connection ID that you are going to create , in ordr to specify the URL that you want to check with the HTTP sensor \
# endpoint is the words after the .com , this is the full url https://gist.github.com/marclamberti/f45f872dea4dfd3eaa015a4a1af4b39b \
# response_check, specify your python function.\
 # poke_interval, frequency that your sensor is going to check if the condition is true or false. every 5 second it will check \
# timeout, after 20 second that the sensor is running, you will receive a timeout and you will receive a failure\
\
\
\'97\
Additional stuff if u use pip install ta\
python -m pip install --upgrade numexpr\
python -m pip install --upgrade pandas\
pip install ta\
\'97\
\
\
After that\
- docker ps\
- copy the container ID of airflow\
- b944e43575fb\
- to enter into the container, type in terminal (find the image that ends with airflow)\
docker exec -it b944e43575fb /bin/bash\
docker exec -it 2c1b31b8d841 /bin/bash\
- \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 {{\NeXTGraphic Screenshot 2022-09-26 at 3.54.33 PM.png \width14520 \height6260 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
\
Test the task in the dag individually, then run the dag to see if it works together\
\
Task checks\
\
1. Check availability of forex rates\
- test the task\
airflow tasks test forex_data_pipeline is_forex_rates_available 2021-01-01\
- airflow tasks test \'93DAG id\'94 \'93task id\'94 execution date in the past \
- if \'93Success criteria met. Exiting.\'94 Then is correct\
\
2. Check availability of file having currencies to watch\
- https://airflow.apache.org/docs/apache-airflow/stable/index.html\
- click on on python api \'97> airflow.sensors \'97> airflow.sensors.filesystem\
- https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/filesystem/index.html\
\
fs_conn_id - means connection to which the path or folder should exist\
Filepath - name of file or folder that you are referring to \
\
- now go back to the airflow UI and do the thing below\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 {{\NeXTGraphic Screenshot 2022-09-26 at 4.17.35 PM.png \width28800 \height18000 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
- type all the stuff u need in the DAG\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 {{\NeXTGraphic Screenshot 2022-09-26 at 4.28.56 PM.png \width7420 \height3620 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
The csv file is in opt/airflow/dags/files/\
\
- then test for success\
airflow tasks test forex_data_pipeline is_forex_currencies_file_available 2021-01-01\
\
\
3. Download forex rates with python\
- uses python operator\
- https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/operators/python/index.html\
- have a python function to download it\
- end point for both currency\
https://gist.githubusercontent.com/marclamberti/f45f872dea4dfd3eaa015a4a1af4b39b/raw/\
- end point for individual currency\
https://gist.githubusercontent.com/marclamberti/f45f872dea4dfd3eaa015a4a1af4b39b/raw/api_forex_exchange_usd.json\
\
\
4. Save the forex rates in HDFS\
- HDFS is used to store big data stuff\
- use bash operator \
- test for success\
airflow tasks test forex_data_pipeline saving_rates 2021-01-01\
\
- on your web browser, go to http://localhost:32762/\
- password and username: \
	root\
\
- the tutorial command is wrong. I corrected it below\
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \cb3 \expnd0\expndtw0\kerning0
    \cf4 saving_rates\cf2  = BashOperator(\cb1 \
\cb3         \cf4 task_id\cf2 =\cf5 "saving_rates"\cf2 ,\cb1 \
\cb3         \cf4 bash_command\cf2 =\cf5 """\cf2 \cb1 \
\cf5 \cb3             hdfs dfs -mkdir -p /user/forex && \cf6 \\\cf2 \cb1 \
\cf5 \cb3             hdfs dfs -put /opt/airflow/dags/files/forex_rates.json /user/forex\cf2 \cb1 \
\cf5 \cb3             """\cf2 \cb1 \
\cb3     )\cb1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0 \cf0 \kerning1\expnd0\expndtw0 \
\
\
\
\
5. Create a hive table to store forex rates from the HDFS\
- we need to be able to interact with the data from the HDFS that we stored, we can use hive to create a table from the data pipeline, which we can then use SQL \
- import hive operator\
https://airflow.apache.org/docs/apache-airflow-providers-apache-hive/stable/_api/airflow/providers/apache/hive/operators/hive/index.html\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 {{\NeXTGraphic Screenshot 2022-09-26 at 6.25.02 PM.png \width18020 \height8260 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
- hql is almost the same as sql\
- need to create the connection\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 {{\NeXTGraphic Screenshot 2022-09-26 at 6.29.54 PM.png \width17420 \height15160 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
6. Process forex rates with spark\
- do the processing in spark, and airflow allows you to trigger that spark job\
https://airflow.apache.org/docs/apache-airflow-providers-apache-spark/stable/_api/airflow/providers/apache/spark/operators/spark_submit/index.html\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 {{\NeXTGraphic Screenshot 2022-09-26 at 7.55.02 PM.png \width12740 \height11820 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
- the tutorial code is wrong, the below one is correct\
\pard\pardeftab720\partightenfactor0

\f1 \cf4 \cb3 \expnd0\expndtw0\kerning0
application\cf2 = \cf5 "dags/scripts/forex_processing.py"\cf2 ,\cb1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0 \cf0 \kerning1\expnd0\expndtw0 \
\
\
7. Send email\
- sign in to this https://security.google.com/settings/security/apppasswords\
- select mail, and mac\
- app password \
vdhnvtjlnzyzqxxi\
- go to mnt/airflow/airflow.cfg , go to smtp \
- put the app password into smtp_password\
\
- exit the container and then type this command\
docker-compose restart airflow\
\
\
8. Send to slack (skipped)\
\
\
9. Set upstream and downstream\
is_forex_rates_available >> is_forex_currencies_file_available >> downloading_rates >> saving_rates \
saving_rates >> creating_forex_rates_table >> forex_processing >> send_email_notification\
}